{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Workshop Python Intro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMuPsz+efoYpJzg8ElS0Ut"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Safe dict reading\n","\n","define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n","\n","```\n","d = {1 : 2, 3 : 4}\n","safe_dict(d, 1) -> 2\n","safe_dict(d, 'cat') -> 0\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}],"source":["def safe_dict(d, k): \n","    for key in d.items():\n","        if k in d:\n","            return d[k]\n","        else: \n","            return 0\n","\n","\n","d = {1 : 2, 3 : 4}\n","\n","print(safe_dict(d, 3))"]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"tl_ZhkbEtiTD"},"source":["# File Reading: Hamlet Exercises\n","\n","Open `hamlet.txt` in the `data` folder\n","\n","### 1. Mentionned Hamlet\n","\n","How many times is hamlet mentioned in the book?\n","\n","Use python and line iteration to count it up"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path = \"C:\\\\Users\\Yuri\\\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\hamlet.txt\"\n","text = open(path, \"r\").readlines()\n","count = 0\n","for line in text:\n","    if 'hamlet' in  line.lower():\n","        count += 1\n","\n","print(count)"]},{"cell_type":"markdown","metadata":{},"source":["### 2. File Reading as a .py program\n","\n","Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n","\n","Then import it in your notebook and call it here."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f = open('yeah.py', 'w')\n","f.writelines(\n","    \"\"\" \n","def count_hamlet():\n","    path = r\"C:\\\\Users\\Yuri\\\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\hamlet.txt\"\n","    text = open(path, \"r\").readlines()\n","    count = 0\n","    for line in text:\n","        if 'hamlet' in  line.lower():\n","            count += 1\n","    return count\n","    \"\"\"\n",")\n","f.close()\n","\n","import yeah as y\n","\n","hamlet_count = y.count_hamlet()\n","\n","print(hamlet_count)"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Unique words in hamlet\n","\n","Write a program that counts the unique words in hamlet."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def counting(file):\n","    count = {}\n","    texte = file.read()\n","    word_list = texte.split()\n","    for word in word_list:\n","        if word in count:\n","            count[word] += 1\n","        else:\n","            count[word] = 1\n","    for key, value in dict(count).items():\n","        if value > 1:\n","            del count[key]\n","    return count\n","\n","\n","path = \"C:\\\\Users\\Yuri\\\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\hamlet.txt\"\n","text = open(path, \"r\")\n","\n","myDict = {}\n","\n","print(counting(text))"]},{"cell_type":"markdown","metadata":{},"source":["# File Reading 2: A Python library.\n","\n","In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n","\n","### 1. File count\n","\n","Count the `py` files in the library using the `os` package"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","path = r\"C:\\\\Users\\\\Yuri\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\csrgraph\"\n","\n","files = os.listdir(path)\n","\n","print (len(files))"]},{"cell_type":"markdown","metadata":{},"source":["### 2. For the following packages, count the number of files that import them:\n","\n","- pandas \n","\n","- numpy\n","\n","- numba"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os \n","\n","root_dir = \"C:\\\\Users\\\\Yuri\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\csrgraph\"\n","\n","keyword = \"import numpy\"\n","\n","count = 0\n","for root, dirs, files in os.walk(root_dir):\n","    for filename in files: #iterate over files\n","        file_path = os.path.join(root, filename) # file path \n","        with open(file_path, 'r') as f: #open the file for reading\n","                for line in f.readlines():\n","                    if keyword in line:\n","                        count += 1\n","print(count)"]},{"cell_type":"markdown","metadata":{},"source":["# First NLP Program: IDF\n","\n","Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n","\n","The IDF formulat is:\n","\n","$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n","\n","Where:\n","\n","- $w$ is the token (unique word),\n","- $n(w)$ is the number of documents that $w$ occurs in,\n","- $N$ is the total number of documents\n","\n","Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n","\n","Example:\n","\n","```\n","IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n","                                                                'interview': -0.4, \n","                                                                'answers': 0.0}\n","\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import sklearn as sk\n","import math \n","import numpy as np\n","\n","\n","\n","corpus = [['interview', 'questions', 'interview'], ['interview', 'answers']]\n","corpus_union = set().union(*corpus)\n","print(corpus_union)\n","\n","wordDict = dict.fromkeys(corpus_union, 0)\n","\n","#bag of word\n","for list in corpus:\n","    for word in list:\n","        wordDict[word] += 1\n","\n","\n","\n","def computeIDF(corpus):\n","    corpus = [set(i) for i in corpus]\n","    idfDict = {}\n","    N = len(corpus)\n","    final_dict = {}\n","    for doc in corpus:\n","        for word in doc:\n","            idfDict[word] = idfDict.get(word, 0) + 1\n","    for word in idfDict:       \n","        final_dict[word] = np.log ( N / (idfDict[word] + 1))\n","    return final_dict\n","\n","#idf = computeIDF([wordDict])\n","\n","print(computeIDF([['interview', 'questions', 'interview'], ['interview', 'answers']]))"]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"82bfnc_KueoX"},"source":["# Stretch Goal: TF-IDF on Hamlet\n","\n","The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\n","\n","Calculate the TF-IDF dictionary on the Hamlet book.\n","\n","What's the TF-IDF of \"Hamlet\"?\n","\n","What's the word with the highest TF-IDF in the book?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd \n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import heapq\n","\n","def tokenize_word():\n","    path = \"C:\\\\Users\\Yuri\\\\Documents\\\\concordia_bootcamp\\\\file_string\\\\m1-4-files-strings\\\\data\\\\hamlet.txt\"\n","    with open(path, 'r') as f: \n","        for line in f: \n","            print(word_tokenize(line))\n","\n","corpus = tokenize_word()\n","\n","\n","def test_():\n","    wordfreq = {}\n","    corpus = tokenize_word()\n","    for token in corpus:\n","        if token not in wordfreq.keys():\n","            wordfreq[token] = 1\n","        else: \n","            wordfreq[token] += 1\n","    return heapq.nlargest(200, wordfreq, key=wordfreq.get)\n","\n","print(test_())\n"]},{"cell_type":"markdown","metadata":{},"source":["# Stretch Goal: Speaker count\n","\n","Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n","\n","Who speaks the most often? Who speaks the least often?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}