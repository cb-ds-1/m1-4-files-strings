{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe dict reading\n",
    "\n",
    "define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n",
    "\n",
    "```\n",
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 1) -> 2\n",
    "safe_dict(d, 'cat') -> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1 : 2, 3 : 4}\n",
    "def safe_dict(d,k):\n",
    "     if k in d:\n",
    "       print(k)\n",
    "     else: return 0\n",
    "safe_dict(d,\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_ZhkbEtiTD"
   },
   "source": [
    "# File Reading: Hamlet Exercises\n",
    "\n",
    "Open `hamlet.txt` in the `data` folder\n",
    "\n",
    "### 1. Mentionned Hamlet\n",
    "\n",
    "How many times is hamlet mentioned in the book?\n",
    "\n",
    "Use python and line iteration to count it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n"
     ]
    }
   ],
   "source": [
    "f = open('data/hamlet.txt', 'r')\n",
    "x=0\n",
    "lignes= f.readlines()\n",
    "for k in lignes:\n",
    "    x+=k.upper().count('HAMLET') \n",
    "f.close()                                                        \n",
    "x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. File Reading as a .py program\n",
    "\n",
    "Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n",
    "\n",
    "Then import it in your notebook and call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamletf.py', 'w') as f:\n",
    "    f.write(\n",
    "\"\"\"\n",
    "def hamletcount(t):\n",
    "    z = open(t, 'r')\n",
    "    x=0\n",
    "    lignes= z.readlines()\n",
    "    for k in lignes:\n",
    "        x+=k.upper().count('HAMLET') \n",
    "    z.close()\n",
    "    return x\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hamletf\n",
    "hamletf.hamletcount('data/hamlet.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unique words in hamlet\n",
    "\n",
    "Write a program that counts the unique words in hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7676\n"
     ]
    }
   ],
   "source": [
    "ensemble=[] \n",
    "with open('data/hamlet.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        for word in line.split():\n",
    "            ensemble.append(word)\n",
    "print(len(set(ensemble)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre de fois d'apparition de { est: 0\n",
      "le nombre de fois d'apparition de . est: 3265\n",
      "le nombre de fois d'apparition de ( est: 0\n",
      "le nombre de fois d'apparition de ) est: 0\n",
      "le nombre de fois d'apparition de , est: 3217\n",
      "le nombre de fois d'apparition de ; est: 387\n",
      "le nombre de fois d'apparition de [ est: 177\n",
      "le nombre de fois d'apparition de ] est: 177\n",
      "le nombre de fois d'apparition de _ est: 384\n",
      "le nombre de fois d'apparition de ! est: 200\n",
      "le nombre de fois d'apparition de ? est: 448\n",
      "le nombre de fois d'apparition de - est: 110\n",
      "le nombre de fois d'apparition de : est: 95\n",
      "le nombre de fois d'apparition de @ est: 0\n",
      "le nombre de fois d'apparition de # est: 0\n",
      "le nombre de fois d'apparition de ^ est: 0\n",
      "le nombre de fois d'apparition de & est: 6\n",
      "le nombre de fois d'apparition de } est: 0\n",
      "le nombre de fois d'apparition de / est: 0\n"
     ]
    }
   ],
   "source": [
    "carspe= [\"{\",\".\",\"(\", \")\",\",\",\";\",\"[\",\"]\",\"_\",\"!\",\"?\",\"-\",\":\",\"@\",\"#\",\"^\",\"&\",\"}\",\"/\"]\n",
    "ensemble=[]\n",
    "a=len(carspe)\n",
    "k = 0\n",
    "for i in range(a):\n",
    "    x= carspe[i]\n",
    "    f= open('data/hamlet.txt', 'r')      \n",
    "    z=0\n",
    "    lignes= f.readlines()\n",
    "    for k in lignes:\n",
    "        z+=k.upper().count(x)\n",
    "        ensemble.append(z)\n",
    "    print(\"le nombre de fois d'apparition de\",x,\"est:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7676\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "count = {}\n",
    "ensemble=[]\n",
    "ensembl=[]\n",
    "with open('data/hamlet.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line)>=1:\n",
    "            cleanline = line.upper().replace(\".\",\" \").replace(\";\", \" \")\n",
    "            cleanline = cleanline.replace(\":\", \" \").replace(\",\", \" \").replace('\"', \" \")\n",
    "            cleanline = cleanline.replace(\"[\", \" \").replace(\"]\", \" \").replace(\"_\", \" \")\n",
    "            cleanline = cleanline.replace(\"-\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\"\\n\", \" \")\n",
    "        for word in line.split():\n",
    "            if word in count :\n",
    "                count[word] += 1\n",
    "                ensemble.append(word)\n",
    "            else:\n",
    "                count[word] = 1\n",
    "                ensembl.append(word)\n",
    "    print(len(set(ensembl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4900 unique words in the book.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile('\\s+')\n",
    "\n",
    "def uniquewords(datafile):\n",
    "    data_file = open(datafile, 'r')\n",
    "    \n",
    "    allwords = []\n",
    "    lines = data_file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line)>1:\n",
    "            cleanline = line.upper().replace(\".\",\" \").replace(\";\", \" \")\n",
    "            cleanline = cleanline.replace(\":\", \" \").replace(\",\", \" \").replace('\"', \" \")\n",
    "            cleanline = cleanline.replace(\"[\", \" \").replace(\"]\", \" \").replace(\"_\", \" \")\n",
    "            cleanline = cleanline.replace(\"-\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\"\\n\", \" \")\n",
    "            for e in regex.split(cleanline.strip()):\n",
    "                allwords.append(e)\n",
    "\n",
    "    data_file.close()\n",
    "    #print(sorted(set(allwords)))   \n",
    "    count_unique=len(set(allwords))\n",
    "    return count_unique\n",
    "\n",
    "print(f\"There are {uniquewords('data/hamlet.txt')} unique words in the book.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading 2: A Python library.\n",
    "\n",
    "In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n",
    "\n",
    "### 1. File count\n",
    "\n",
    "Count the `py` files in the library using the `os` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Count the py files in the library using the os package\n",
    "import os\n",
    "listfiles = os.listdir('data/csrgraph')\n",
    "count=0\n",
    "for i in range(len(listfiles)):\n",
    "    if listfiles[i].endswith('.py'):\n",
    "        count+=1\n",
    "print(count)\n",
    "#print(os.listdir('data/csrgraph'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For the following packages, count the number of files that import them:\n",
    "\n",
    "- pandas \n",
    "\n",
    "- numpy\n",
    "\n",
    "- numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files Pandas 4\n",
      "The number of files numpy 6\n",
      "The number of files numba 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def countimports(package,directory):\n",
    "    listfiles = os.listdir(directory)\n",
    "    countfiles=0\n",
    "    for i in range(len(listfiles)):\n",
    "        if listfiles[i].endswith('.py'):\n",
    "            filepath = directory+'/'+listfiles[i]\n",
    "            with open(filepath, 'r') as f:\n",
    "                readfile = f.read().replace('\\n', '')\n",
    "                if readfile.find(package) != -1:\n",
    "                    countfiles+=1\n",
    "    return countfiles\n",
    "\n",
    "print(\"The number of files Pandas\",countimports('pandas','data/csrgraph'))\n",
    "print(\"The number of files numpy\",countimports('numpy','data/csrgraph'))\n",
    "print(\"The number of files numba\",countimports('numba','data/csrgraph'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First NLP Program: IDF\n",
    "\n",
    "Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n",
    "\n",
    "The IDF formulat is:\n",
    "\n",
    "$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the token (unique word),\n",
    "- $n(w)$ is the number of documents that $w$ occurs in,\n",
    "- $N$ is the total number of documents\n",
    "\n",
    "Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n",
    "                                                                'interview': -0.4, \n",
    "                                                                'answers': 0.0}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': 0.0, 'interview': -0.40546510810816444, 'questions': 0.0}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function, idf(docs) that takes in a list of lists of words \n",
    "# and returns a dictionary word -> idf score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def idf(docs):\n",
    "    tokens=np.unique(docs)\n",
    "        \n",
    "    nlist=[]\n",
    "    for w in tokens:\n",
    "        n=0\n",
    "        for doc in docs:\n",
    "            strtoken = ' '.join(doc)\n",
    "            if strtoken.find(w) != -1:\n",
    "                n+=1\n",
    "        nlist.append((w,n))\n",
    "\n",
    "    k,v = [],[]\n",
    "    for i in range(len(nlist)):\n",
    "        k.append(nlist[i][0])\n",
    "        n = nlist[i][1]\n",
    "        v.append(np.log(len(docs)/(1+(n))))\n",
    "\n",
    "    return dict(zip(k,v))\n",
    "\n",
    "# Test Scenarios & print result \n",
    "\n",
    "docs=([['interview', 'questions'], ['interview', 'answers']])\n",
    "idf(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82bfnc_KueoX"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-178-bc72a399f965>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-178-bc72a399f965>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Stretch Goal: TF-IDF on Hamlet\n",
    "\n",
    "The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\n",
    "\n",
    "Calculate the TF-IDF dictionary on the Hamlet book.\n",
    "\n",
    "What's the TF-IDF of \"Hamlet\"?\n",
    "\n",
    "What's the word with the highest TF-IDF in the book?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goal: Speaker count\n",
    "\n",
    "Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n",
    "\n",
    "Who speaks the most often? Who speaks the least often?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMuPsz+efoYpJzg8ElS0Ut",
   "collapsed_sections": [],
   "name": "Workshop Python Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
