{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Martin Dionne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg811t1qthd4"
   },
   "source": [
    "# Warmup: Counter. \n",
    "\n",
    "Count how many times each element in a list occurs.\n",
    "\n",
    "```\n",
    "[1, 3, 2, 1, 5, 3, 5, 1, 4] â‡’\n",
    "\n",
    "    1: 3 times\n",
    "    2: 1 time\n",
    "    3: 2 times\n",
    "    4: 1 time\n",
    "    5: 2 times\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_counter(l): \n",
    "    d = {}\n",
    "    for key in set(l):\n",
    "        if l.count(key) <= 1:\n",
    "            d[key] = str(l.count(key)) + \" time\" \n",
    "        else:\n",
    "            d[key] = str(l.count(key)) + \" times\" \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '3 times', 2: '1 time', 3: '2 times', 4: '1 time', 5: '2 times'}\n"
     ]
    }
   ],
   "source": [
    "print(key_counter([1, 3, 2, 1, 5, 3, 5, 1, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe dict reading\n",
    "\n",
    "define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n",
    "\n",
    "```\n",
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 1) -> 2\n",
    "safe_dict(d, 'cat') -> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_dict = lambda d, k: d[k] if k in d else 0\n",
    "\n",
    "# or\n",
    "#def safe_dict(d, k):\n",
    "#    return d[k] if k in d else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "d = {1 : 2, 3 : 4}\n",
    "print(safe_dict(d, 1))      # 2\n",
    "print(safe_dict(d, 'cat'))  # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_ZhkbEtiTD"
   },
   "source": [
    "# File Reading: Hamlet Exercises\n",
    "\n",
    "Open `hamlet.txt` in the `data` folder\n",
    "\n",
    "### 1. Mentionned Hamlet\n",
    "\n",
    "How many times is hamlet mentioned in the book?\n",
    "\n",
    "Use python and line iteration to count it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "f = open('data/hamlet.txt', 'r')\n",
    "txt = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet is mentionned 111 times\n",
      "HAMLET speaks 363 times\n",
      "The word 'hamlet' appears 474 times in total\n"
     ]
    }
   ],
   "source": [
    "print(\"Hamlet is mentionned \" + str(txt.count(\"Hamlet\")) + \" times\")\n",
    "print(\"HAMLET speaks \" + str(txt.count(\"HAMLET\")) + \" times\")\n",
    "print(\"The word 'hamlet' appears \" + str(txt.count(\"HAMLET\") + txt.count(\"Hamlet\")) + \" times in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. File Reading as a .py program\n",
    "\n",
    "Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n",
    "\n",
    "Then import it in your notebook and call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file: python hamlet.py (in the terminal)\n",
    "# write the file\n",
    "with open('hamlet.py', 'w') as f:\n",
    "    f.write(\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "def mentionned(word):\n",
    "    \n",
    "    with open(\"data/hamlet.txt\", \"r\") as f:\n",
    "        txt = f.read().lower()\n",
    "        word_count = txt.count(word.lower())\n",
    "        return word_count\n",
    "\"\"\")\n",
    "\n",
    "# show py file\n",
    "#with open('hamlet.py', 'r') as f:\n",
    "#    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'hamlet' appears 474 times in total\n"
     ]
    }
   ],
   "source": [
    "# load and execute\n",
    "import hamlet\n",
    "\n",
    "print(f\"The word 'hamlet' appears {hamlet.mentionned('Hamlet')} times in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unique words in hamlet\n",
    "\n",
    "Write a program that counts the unique words in hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def unique_words():\n",
    "\n",
    "    with open(\"data/hamlet.txt\", \"r\") as f:\n",
    "        hamlet = []\n",
    "\n",
    "        for line in f.readlines():\n",
    "            hamlet += line.lower().split()\n",
    "\n",
    "        #docs = [ line.lower().split() for line in f.readlines() ]\n",
    "        #unique_words = set([item for sublist in docs for item in sublist])\n",
    "        \n",
    "    return len(set(hamlet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7092"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the words in the document not the words spoken in the play\n",
    "unique_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading 2: A Python library.\n",
    "\n",
    "In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n",
    "\n",
    "### 1. File count\n",
    "\n",
    "Count the `py` files in the library using the `os` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "len(os.listdir('data/csrgraph/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For the following packages, count the number of files that import them:\n",
    "\n",
    "- pandas \n",
    "\n",
    "- numpy\n",
    "\n",
    "- numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def pkg_imported(directory, pkg):\n",
    "    \"\"\" count the number of files using a specific python package \n",
    "        usage : pkg_imported(directory, pkg)\n",
    "    \"\"\"\n",
    "    # list the files\n",
    "    files = os.listdir(directory)\n",
    "    count = 0\n",
    "\n",
    "    for file in files:\n",
    "        found = False\n",
    "        #open files and read each lines\n",
    "        with open(directory + file , 'r') as f:     \n",
    "            for line in f.readlines():\n",
    "                if pkg in line: \n",
    "                    found = True \n",
    "                    break\n",
    "        if found: count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 files use pandas\n",
      "6 files use numpy\n",
      "6 files use numba\n"
     ]
    }
   ],
   "source": [
    "print( f\"{pkg_imported('data/csrgraph/', 'pandas')} files use pandas\" )\n",
    "print( f\"{pkg_imported('data/csrgraph/', 'numpy')} files use numpy\" )\n",
    "print( f\"{pkg_imported('data/csrgraph/', 'numba')} files use numba\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First NLP Program: IDF\n",
    "\n",
    "Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n",
    "\n",
    "The IDF formulat is:\n",
    "\n",
    "$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the token (unique word),\n",
    "- $n(w)$ is the number of documents that $w$ occurs in,\n",
    "- $N$ is the total number of documents\n",
    "\n",
    "Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n",
    "                                                                'interview': -0.4, \n",
    "                                                                'answers': 0.0}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def TF(doc):\n",
    "    unique_words = set(doc)\n",
    "    # fill tf dict with the occurence of w\n",
    "    tf = {}\n",
    "    for w in unique_words:\n",
    "        tf[w] = doc.count(w)\n",
    "    return tf\n",
    "\n",
    "\n",
    "# this version can handle single and multiple docs\n",
    "def IDF(docs):\n",
    "\n",
    "    n = {}\n",
    "    # if a list of doc is feeded\n",
    "    if type(docs[0]) == list:\n",
    "\n",
    "        # flaten docs and create set of unique words (w) in docs\n",
    "        unique_words = set([item for sublist in docs for item in sublist])\n",
    "        \n",
    "        # fill tf dict with the number of docs that w occurs in\n",
    "        for w in unique_words:\n",
    "            n[w] = sum( [True if sublist.count(w) >= 1 else False for sublist in docs ] )\n",
    "\n",
    "    # if a single doc is feeded\n",
    "    else:\n",
    "        unique_words = set(docs)\n",
    "        # fill n dict with the occurence of w\n",
    "        for w in unique_words:\n",
    "            n[w] = docs.count(w)\n",
    "\n",
    "    # store N value\n",
    "    N = len(docs)\n",
    "\n",
    "    # fill n dict with idf values for each w\n",
    "    idf = {}\n",
    "    for w in unique_words:\n",
    "        idf[w] = round(math.log(N / (1 + n[w])), 1)\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interview': -0.4, 'answers': 0.0, 'questions': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF([['interview', 'questions'], ['interview', 'answers']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82bfnc_KueoX"
   },
   "source": [
    "# Stretch Goal: IDF on Hamlet\n",
    "\n",
    "Calculate the IDF dictionary on the Hamlet book.\n",
    "\n",
    "What's the IDF of \"Hamlet\"?\n",
    "\n",
    "What's the word with the highest IDF in the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import file\n",
    "with open('data/hamlet.txt', 'r') as f:\n",
    "    hamlet = []\n",
    "    for line in f.readlines():\n",
    "        line = line.lower()\n",
    "        hamlet += line.split()\n",
    "\n",
    "tf = TF(hamlet)\n",
    "idf = IDF(hamlet)\n",
    "\n",
    "tf_idf = {}\n",
    "for w in tf:\n",
    "    tf_idf[w] = round(tf[w]/idf[w], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the TF-IDF of 'Hamlet'?\n",
      "4.1\n",
      "\n",
      "What's the word with the highest TF-IDF in the book?\n",
      "('the', 325.3)\n"
     ]
    }
   ],
   "source": [
    "#print(\"Calculate the TF-IDF dictionary on the Hamlet book.\")\n",
    "#print(sorted(((value,key) for (key,value) in tf_idf.items()), reverse=True)[0:10])\n",
    "#print('')\n",
    "\n",
    "print(\"What's the TF-IDF of 'Hamlet'?\")\n",
    "print( str(tf_idf[\"hamlet\"]) )\n",
    "print('')\n",
    "\n",
    "print(\"What's the word with the highest TF-IDF in the book?\")\n",
    "print(sorted(tf_idf.items(), key=lambda x: x[1], reverse=True)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goal: Speaker count\n",
    "\n",
    "Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n",
    "\n",
    "Who speaks the most often? Who speaks the least often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# regex to get words with multiple letter in caps\n",
    "regex = r\"\\b[A-Z][A-Z]+\\b\"\n",
    "\n",
    "with open('data/hamlet.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "    matches = re.findall(regex, txt)\n",
    "\n",
    "tf = TF(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('HAMLET', 363), ('HORATIO', 111), ('KING', 106), ('POLONIUS', 87), ('QUEEN', 74), ('LAERTES', 63), ('OPHELIA', 59), ('ROSENCRANTZ', 50), ('CLOWN', 45), ('FIRST', 44), ('MARCELLUS', 36), ('GUILDENSTERN', 34), ('OSRIC', 27), ('BARNARDO', 22), ('SCENE', 21), ('PLAYER', 17), ('GHOST', 15), ('REYNALDO', 14), ('II', 12), ('SECOND', 12), ('ACT', 10), ('FRANCISCO', 9), ('III', 8), ('IV', 8), ('FORTINBRAS', 7), ('CAPTAIN', 7), ('GENTLEMAN', 3), ('VOLTEMAND', 3), ('LORD', 3), ('MESSENGER', 2), ('PRIEST', 2), ('VI', 2), ('SAILOR', 2), ('DANES', 2), ('VII', 2), ('CORNELIUS', 2), ('OF', 2), ('THE', 1), ('TRAGEDY', 1), ('LORDS', 1), ('LUCIANUS', 1), ('BOTH', 1), ('ALL', 1), ('PRINCE', 1), ('SERVANT', 1), ('DENMARK', 1), ('CLAUDIUS', 1), ('AMBASSADOR', 1), ('PROLOGUE', 1), ('GERTRUDE', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(tf.items(), key=lambda x: x[1], reverse=True))\n",
    "# Hamlet speaks the most often \n",
    "# Ambassador, Claudius, Gertrude, Lucianus, Prince, Servant speak once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMuPsz+efoYpJzg8ElS0Ut",
   "collapsed_sections": [],
   "name": "Workshop Python Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
