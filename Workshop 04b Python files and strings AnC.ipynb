{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anne Cloutier Python Files workshop GitHub: Vetiver5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe dict reading\n",
    "\n",
    "define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n",
    "\n",
    "```\n",
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 1) -> 2\n",
    "safe_dict(d, 'cat') -> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from = {1: 2, 3 : 4, 5 : 6, 7 : 8}\n",
    "\n",
    "def safe_dict(read_from, k): \n",
    "    if k in read_from:\n",
    "        print(read_from[k])\n",
    "    else :\n",
    "        print(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "safe_dict(read_from, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_ZhkbEtiTD"
   },
   "source": [
    "# File Reading: Hamlet Exercises\n",
    "\n",
    "Open `hamlet.txt` in the `data` folder\n",
    "\n",
    "### 1. Mentionned Hamlet\n",
    "\n",
    "How many times is hamlet mentioned in the book?\n",
    "\n",
    "Use python and line iteration to count it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of the word Hamlet: 111\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "file = open('/Users/annecloutier/Desktop/strings__hamlet/hamlet.txt', 'r')\n",
    "data = file.read()\n",
    "occurences = data.count(\"Hamlet\")\n",
    "\n",
    "print('Number of occurences of the word Hamlet:' , occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unique words in hamlet\n",
    "\n",
    "Write a program that counts the unique words in hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7092\n"
     ]
    }
   ],
   "source": [
    "text = open('/Users/annecloutier/Desktop/strings__hamlet/hamlet.txt', \"r\")\n",
    "\n",
    "lines = text.readlines()\n",
    "\n",
    "book_set = set()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.lower()\n",
    "    words = line.split(\" \")\n",
    "    line_set = set(words)\n",
    "    book_set = book_set.union(line_set)\n",
    "\n",
    "print(len(book_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading 2: A Python library.\n",
    "\n",
    "In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n",
    "\n",
    "### 1. File count\n",
    "\n",
    "Count the `py` files in the library using the `os` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grarep.py',\n",
       " 'ggvec.py',\n",
       " 'version.py',\n",
       " 'methods.py',\n",
       " 'graph.py',\n",
       " 'random_walks.py',\n",
       " '__init__.py',\n",
       " 'glove.py']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"/Users/annecloutier/Desktop/GitHub/m1-4-files-strings/data/csrgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "count = 0\n",
    "\n",
    "list = os.listdir(\"/Users/annecloutier/Desktop/GitHub/m1-4-files-strings/data/csrgraph\")\n",
    "number_files = len(list)\n",
    "print(number_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For the following packages, count the number of files that import them:\n",
    "\n",
    "- pandas \n",
    "\n",
    "- numpy\n",
    "\n",
    "- numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pandas': 4, 'numpy': 6, 'numba': 6}\n"
     ]
    }
   ],
   "source": [
    "def count_packages(kind):\n",
    "    path = \"/Users/annecloutier/Desktop/GitHub/m1-4-files-strings/data/csrgraph\"\n",
    "    fileslist = os.listdir(path)\n",
    "    \n",
    "    packages = {'pandas' :0, 'numpy':0, 'numba':0}\n",
    "    \n",
    "    for f in fileslist:\n",
    "        file = open(path + \"/\" + f, 'r')\n",
    "        read = file.read()\n",
    "        for p in packages:\n",
    "            if p in read:\n",
    "                packages[p] +=1\n",
    "        \n",
    "    return packages\n",
    "\n",
    "print(count_packages(\"/Users/annecloutier/Desktop/GitHub/m1-4-files-strings/data/csrgraph\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First NLP Program: IDF\n",
    "\n",
    "Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n",
    "\n",
    "The IDF formulat is:\n",
    "\n",
    "$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the token (unique word),\n",
    "- $n(w)$ is the number of documents that $w$ occurs in,\n",
    "- $N$ is the total number of documents\n",
    "\n",
    "Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n",
    "                                                                'interview': -0.4, \n",
    "                                                                'answers': 0.0}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'interview': 4, 'question': 0, 'answers': 0}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "big_list = [['interview', 'question'], ['interview', 'answers']]\n",
    "answer_dict = {'interview':2,'question':0,'answers':0}\n",
    "\n",
    "for l in big_list:\n",
    "    for k in answer_dict:\n",
    "        if k in l:\n",
    "            answer_dict[k] +=1\n",
    "            break\n",
    "\n",
    "for k in answer_dict:\n",
    "    if k in big_list:\n",
    "        answer_dict[k] = math.log(2/(answer_dict[k]+1))\n",
    "        \n",
    "print(answer_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82bfnc_KueoX"
   },
   "source": [
    "# Stretch Goal: TF-IDF on Hamlet\n",
    "\n",
    "The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\n",
    "\n",
    "Calculate the TF-IDF dictionary on the Hamlet book.\n",
    "\n",
    "What's the TF-IDF of \"Hamlet\"?\n",
    "\n",
    "What's the word with the highest TF-IDF in the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goal: Speaker count\n",
    "\n",
    "Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n",
    "\n",
    "Who speaks the most often? Who speaks the least often?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMuPsz+efoYpJzg8ElS0Ut",
   "collapsed_sections": [],
   "name": "Workshop Python Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
