{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dylan Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe dict reading\n",
    "\n",
    "define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n",
    "\n",
    "```\n",
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 1) -> 2\n",
    "safe_dict(d, 'cat') -> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_dict(d, k):\n",
    "    '''\n",
    "    This function takes in a python dict 'd' and a key 'k'\n",
    "    and makes it safe to read, even with keys that\n",
    "    aren't in the dictionary.\n",
    "    '''\n",
    "    try:\n",
    "        d[k]\n",
    "    except KeyError as ke:\n",
    "        return 0\n",
    "    return d[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_ZhkbEtiTD"
   },
   "source": [
    "# File Reading: Hamlet Exercises\n",
    "\n",
    "Open `hamlet.txt` in the `data` folder\n",
    "\n",
    "### 1. Mentionned Hamlet\n",
    "\n",
    "How many times is hamlet mentioned in the book?\n",
    "\n",
    "Use python and line iteration to count it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/dylan/Downloads/m1-4-files-strings-main/m1-4-files-strings-main/data/hamlet.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for word in words:\n",
    "    if \"hamlet\" in word.lower():\n",
    "        count += 1\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. File Reading as a .py program\n",
    "\n",
    "Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n",
    "\n",
    "Then import it in your notebook and call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Hamlet_Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamlet_Counter.hamlet_counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unique words in hamlet\n",
    "\n",
    "Write a program that counts the unique words in hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7676"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading 2: A Python library.\n",
    "\n",
    "In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n",
    "\n",
    "### 1. File count\n",
    "\n",
    "Count the `py` files in the library using the `os` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/dylan/Downloads/m1-4-files-strings-main/m1-4-files-strings-main/data/csrgraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".py\"): py_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For the following packages, count the number of files that import them:\n",
    "\n",
    "- pandas \n",
    "\n",
    "- numpy\n",
    "\n",
    "- numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/dylan/Downloads/m1-4-files-strings-main/m1-4-files-strings-main/data/csrgraph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_count = 0\n",
    "numpy_count = 0\n",
    "numba_count = 0\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    \n",
    "    path += file\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        data = file.read()\n",
    "        \n",
    "    words = data.split()\n",
    "    \n",
    "    # Reset flags\n",
    "    contains_pandas = False\n",
    "    contains_numpy = False\n",
    "    contains_numba = False\n",
    "    \n",
    "    # Check if package is imported\n",
    "    for word in words:\n",
    "        if word == 'pandas': contains_pandas = 'True'\n",
    "        if word == 'numpy': contains_numpy = 'True'\n",
    "        if word == 'numba': contains_numba = 'True'\n",
    "    \n",
    "    # Increment counters\n",
    "    if (contains_pandas): pandas_count += 1\n",
    "    if (contains_numpy): numpy_count += 1\n",
    "    if (contains_numba): numba_count += 1\n",
    "        \n",
    "    # Reset path\n",
    "    path = 'C:/Users/dylan/Downloads/m1-4-files-strings-main/m1-4-files-strings-main/data/csrgraph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First NLP Program: IDF\n",
    "\n",
    "Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n",
    "\n",
    "The IDF formulat is:\n",
    "\n",
    "$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the token (unique word),\n",
    "- $n(w)$ is the number of documents that $w$ occurs in,\n",
    "- $N$ is the total number of documents\n",
    "\n",
    "Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n",
    "                                                                'interview': -0.4, \n",
    "                                                                'answers': 0.0}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF(docs):\n",
    "    '''\n",
    "    Given a list of words, this function returns the\n",
    "    Inverse Document Frequency (IDF).\n",
    "    '''\n",
    "    N = len(docs)\n",
    "    tokens = []\n",
    "    \n",
    "    for lst in docs:\n",
    "        for ele in lst:\n",
    "            tokens.append(ele)\n",
    "    \n",
    "    n_w = dict.fromkeys(tokens, 0) #number of documents w occurs in\n",
    "    idf = dict.fromkeys(tokens, 0) #idf of each token\n",
    "\n",
    "    for token in tokens:\n",
    "        n_w[token] += 1\n",
    "        idf[token] = math.log(N / (1 + n_w[token]))\n",
    "    \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interview': -0.40546510810816444, 'questions': 0.0, 'answers': 0.0}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF([['interview', 'questions'], ['interview', 'answers']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82bfnc_KueoX"
   },
   "source": [
    "# Stretch Goal: TF-IDF on Hamlet\n",
    "\n",
    "The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\n",
    "\n",
    "Calculate the TF-IDF dictionary on the Hamlet book.\n",
    "\n",
    "What's the TF-IDF of \"Hamlet\"?\n",
    "\n",
    "What's the word with the highest TF-IDF in the book?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goal: Speaker count\n",
    "\n",
    "Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n",
    "\n",
    "Who speaks the most often? Who speaks the least often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMuPsz+efoYpJzg8ElS0Ut",
   "collapsed_sections": [],
   "name": "Workshop Python Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
